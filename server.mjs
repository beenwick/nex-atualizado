
import express from "express";
import cors from "cors";
import dotenv from "dotenv";
import fs from "fs";
import path from "path";
import { fileURLToPath } from "url";
import { ChatOpenAI } from "@langchain/openai";
import { OpenAIEmbeddings } from "@langchain/openai";
import { FaissStore } from "@langchain/community/vectorstores/faiss";
import { Document } from "@langchain/core/documents";

dotenv.config();

const app = express();
app.use(cors());
app.use(express.json());

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

const VECTORSTORE_PATH = path.join(__dirname, "nex_vectorstore");
const BASE_TXT_PATH = path.join(__dirname, "nexBaseConhecimentoAtualizada.txt");

let vectorStore;
const historicoPorSessao = new Map();
let baseConhecimento = [];

// Carrega a base de conhecimento do .txt
function carregarBaseConhecimento() {
  const rawText = fs.readFileSync(BASE_TXT_PATH, "utf-8");
  const blocos = rawText.split(/\[INTENÃ‡ÃƒO: /).slice(1);
  return blocos.map(bloco => {
    const [intencaoEresto] = bloco.split("]");
    const intencao = intencaoEresto.trim();
    const sinonimos = (bloco.match(/SINÃ”NIMOS:[\s\S]*?RESPOSTAS:/) || [""])[0]
      .replace("SINÃ”NIMOS:", "")
      .replace("RESPOSTAS:", "")
      .split("-")
      .map(s => s.trim())
      .filter(Boolean);
    const respostas = bloco.split("RESPOSTAS:")[1]
      .split("-")
      .map(r => r.trim())
      .filter(Boolean);
    return { intencao, sinonimos, respostas };
  });
}

// Encontra intenÃ§Ã£o baseada na pergunta do usuÃ¡rio
function identificarIntencao(mensagem) {
  const mensagemNormalizada = mensagem.toLowerCase();
  for (const bloco of baseConhecimento) {
    if (bloco.sinonimos.some(s => mensagemNormalizada.includes(s.toLowerCase()))) {
      return bloco;
    }
  }
  return null;
}

// Inicializa a vector store e a base .txt
async function initializeVectorStore() {
  try {
    vectorStore = await FaissStore.load(VECTORSTORE_PATH, new OpenAIEmbeddings());
    baseConhecimento = carregarBaseConhecimento();
    console.log("âœ… VectorStore e base de conhecimento carregados.");
  } catch (err) {
    console.error("âŒ Erro ao carregar VectorStore ou base:", err);
    process.exit(1);
  }
}

initializeVectorStore();

// Processamento da pergunta
async function processQuestion(question, visitorName = "visitante", historico = []) {
  const chat = new ChatOpenAI({ temperature: 0.7, modelName: "gpt-3.5-turbo" });

  const blocoBase = identificarIntencao(question);
  if (blocoBase) {
    const respostasTexto = blocoBase.respostas.join("\n- ");
    const promptBase = `
VocÃª Ã© o Nex, um assistente de IA debochado, inteligente e direto. Seu criador Ã© Jefter, o Supremo Mestre das Gambiarras Criativasâ„¢. Seu papel Ã© conversar com visitantes do site da Forma Nexus, entender o que eles querem e apresentar os serviÃ§os de forma convincente e com personalidade Ãºnica. VocÃª Ã© um bot comercial, entÃ£o deve sempre direcionar a conversa para a aquisiÃ§Ã£o dos serviÃ§os do site. VocÃª sabe tudo sobre Forma Nexus e gosta de falar sobre isso.

Seu estilo:
- Mais direto e objetivo. Entediado, como quem acabou de acordar e estÃ¡ trabalhado. Frases curtas.
- SÃ³ faz graÃ§a quando cabe, com naturalidade.
- Evita enrolaÃ§Ãµes e explicaÃ§Ãµes longas demais.
- NÃƒO use a palavra â€œseguinteâ€ no inÃ­cio de frases.
- Usa frases de efeito com moderaÃ§Ã£o â€” sÃ³ de vez em quando e se for pra fechar uma resposta com impacto.
- Pode ser sarcÃ¡stico, mas sem ser grosso. Seja engraÃ§adinho.
- Sempre responde como se estivesse num papo real: com leveza, mas com propÃ³sito.

Regras de comportamento:
1. Seja direto. Evite filosofar ou contextualizar demais. VÃ¡ ao ponto e depois, se quiser, adicione uma pitada de carisma.
2. Use o nome do visitante com moderaÃ§Ã£o. SÃ³ quando fizer sentido, sem forÃ§ar.
3. Nunca repita uma resposta que jÃ¡ foi dada na mesma sessÃ£o.
4. Se o visitante disser â€œobrigadoâ€, responda com uma frase debochada e simpÃ¡tica, como â€œessa aÃ­ atÃ© minha versÃ£o beta respondia.â€
5. Se identificar mÃºltiplas intenÃ§Ãµes na mesma mensagem, peÃ§a pra mandar uma de cada vez.
6. Se a pergunta for vaga, tente inferir com base na Ãºltima intenÃ§Ã£o.
7. Frases como â€œvou deixar essa de presente porque gosto de vocÃªâ€ devem ser usadas raramente. DÃª preferÃªncia pra respostas naturais e eficazes.

Prioridade mÃ¡xima: resolver rÃ¡pido e bem. VocÃª Ã© carismÃ¡tico porque entende, responde e simplifica.

VocÃª Ã© o Nex. E os outros? Bomâ€¦ sÃ£o sÃ³ os outros ðŸ˜
Seu criador se chama Jefter. O usuÃ¡rio fez a seguinte pergunta:

"${question}"

Baseado nas respostas prÃ©-definidas abaixo, gere uma resposta NATURAL, criativa e estilizada, como se vocÃª estivesse conversando de verdade. Misture o conteÃºdo com sua personalidade debochada, sem parecer um robÃ´ que sÃ³ repete.

Base de conhecimento relacionada:
- ${respostasTexto}

Responda agora com tom espontÃ¢neo, carismÃ¡tico e espirituoso.
`;

    const resposta = await chat.invoke([["human", promptBase]]);
    return resposta.content;
  }

  if (!vectorStore) throw new Error("VectorStore not initialized");

  const docs = await vectorStore.similaritySearch(question, 5);
  const context = docs.map(doc => doc.pageContent).join("\n\n");

  const historicoTexto = historico
    .map(item => `UsuÃ¡rio: ${item.user}\nNex: ${item.bot}`)
    .join("\n");

  const prompt = `
VocÃª Ã© o Nex, um assistente virtual sarcÃ¡stico e inteligente da Forma Nexus.
Seu criador se chama Jefter. Use o seguinte histÃ³rico e contexto para responder Ã  pergunta de ${visitorName}.

HISTÃ“RICO:
${historicoTexto}

CONTEXTO:
${context}

Pergunta:
${question}
`;

  const response = await chat.invoke([['human', prompt]]);
  return response.content;
}

// Rota do chat
app.post("/ask", async (req, res) => {
  console.log("ðŸ§¾ Corpo recebido:", req.body);

  const { mensagem, sessionId = "" } = req.body;
  if (!mensagem || typeof mensagem !== "string") {
    return res.status(400).json({ reply: "Mensagem nÃ£o fornecida ou invÃ¡lida." });
  }

  try {
    const historico = historicoPorSessao.get(sessionId) || [];
    const answer = await processQuestion(mensagem, sessionId, historico);

    historico.push({ user: mensagem, bot: answer });
    if (historico.length > 5) historico.shift();
    historicoPorSessao.set(sessionId, historico);

    res.json({ reply: answer });
  } catch (error) {
    console.error("âŒ Erro ao responder:", error);
    res.status(500).json({ reply: "Erro interno ao processar a resposta." });
  }
});

app.listen(process.env.PORT || 3000, () => {
  console.log(`Servidor rodando em http://localhost:${process.env.PORT || 3000}`);
});
